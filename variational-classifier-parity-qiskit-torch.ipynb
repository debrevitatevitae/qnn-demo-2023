{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install qiskit\n",
    "!pip install qiskit-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter, ParameterVector\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.optim import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the quantum circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(W):\n",
    "    \"\"\"Applies a layer of arbitrary rotations and circular entanglements to the variational circuit\n",
    "\n",
    "    Args:\n",
    "        W (np.ndarray): rotation parameters for the layer\n",
    "    \"\"\"\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "\n",
    "    for i in range(n_qubits):\n",
    "        qc.rz(W[i*3], i)\n",
    "        qc.ry(W[i*3 + 1], i)\n",
    "        qc.rz(W[i*3 + 2], i)\n",
    "\n",
    "    for i in range(n_qubits-1):\n",
    "        qc.cnot(i, i+1)\n",
    "\n",
    "    if n_qubits > 2:\n",
    "        qc.cnot(n_qubits-1, 0)\n",
    "\n",
    "    return qc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Qiskit, there is not basis state preparation circuit and anyway we need to work with `Parameter` objects to use the `qiskit-machine-learning` tools. So we just encode $R_Y$ rotation, pass the parameters and multiply by $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_phase_gate(qc, phase, qubit):\n",
    "    qc.p(phase, qubit)\n",
    "    qc.x(qubit)\n",
    "    qc.p(phase, qubit)\n",
    "    qc.x(qubit)\n",
    "\n",
    "\n",
    "def statepreparation(x):\n",
    "    \"\"\"Prepares the binary state fed to the vqc\n",
    "\n",
    "    Args:\n",
    "        x (List): list of 0s and 1s corresponding to the basis state\n",
    "    \"\"\"\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    \n",
    "    for i, x_i in enumerate(x):\n",
    "        qc.rx(x_i * np.pi, i)\n",
    "        global_phase_gate(qc, -np.pi/2, i)\n",
    "\n",
    "\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 2\n",
    "\n",
    "weight_params = ParameterVector(name='W', length=3 * n_qubits * n_layers)\n",
    "input_params = ParameterVector(name='x', length=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the quantum circuit\n",
    "qc = QuantumCircuit(n_qubits)\n",
    "qc = qc.compose(statepreparation(input_params))\n",
    "for l in range(n_layers):\n",
    "    qc = qc.compose(layer(weight_params[3 * n_qubits * l: 3 * n_qubits * (l+1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">     ┌────────────┐┌─────────┐┌───┐┌─────────┐┌───┐┌──────────┐ ┌──────────┐»\n",
       "q_0: ┤ Rx(π*x[0]) ├┤ P(-π/2) ├┤ X ├┤ P(-π/2) ├┤ X ├┤ Rz(W[0]) ├─┤ Ry(W[1]) ├»\n",
       "     ├────────────┤├─────────┤├───┤├─────────┤├───┤├──────────┤ ├──────────┤»\n",
       "q_1: ┤ Rx(π*x[1]) ├┤ P(-π/2) ├┤ X ├┤ P(-π/2) ├┤ X ├┤ Rz(W[3]) ├─┤ Ry(W[4]) ├»\n",
       "     ├────────────┤├─────────┤├───┤├─────────┤├───┤├──────────┤ ├──────────┤»\n",
       "q_2: ┤ Rx(π*x[2]) ├┤ P(-π/2) ├┤ X ├┤ P(-π/2) ├┤ X ├┤ Rz(W[6]) ├─┤ Ry(W[7]) ├»\n",
       "     ├────────────┤├─────────┤├───┤├─────────┤├───┤├──────────┤┌┴──────────┤»\n",
       "q_3: ┤ Rx(π*x[3]) ├┤ P(-π/2) ├┤ X ├┤ P(-π/2) ├┤ X ├┤ Rz(W[9]) ├┤ Ry(W[10]) ├»\n",
       "     └────────────┘└─────────┘└───┘└─────────┘└───┘└──────────┘└───────────┘»\n",
       "«      ┌──────────┐                       ┌───┐┌───────────┐┌───────────┐»\n",
       "«q_0: ─┤ Rz(W[2]) ├──■────────────────────┤ X ├┤ Rz(W[12]) ├┤ Ry(W[13]) ├»\n",
       "«      ├──────────┤┌─┴─┐     ┌───────────┐└─┬─┘├───────────┤├───────────┤»\n",
       "«q_1: ─┤ Rz(W[5]) ├┤ X ├──■──┤ Rz(W[15]) ├──┼──┤ Ry(W[16]) ├┤ Rz(W[17]) ├»\n",
       "«      ├──────────┤└───┘┌─┴─┐└───────────┘  │  ├───────────┤├───────────┤»\n",
       "«q_2: ─┤ Rz(W[8]) ├─────┤ X ├──────■────────┼──┤ Rz(W[18]) ├┤ Ry(W[19]) ├»\n",
       "«     ┌┴──────────┤     └───┘    ┌─┴─┐      │  ├───────────┤├───────────┤»\n",
       "«q_3: ┤ Rz(W[11]) ├──────────────┤ X ├──────■──┤ Rz(W[21]) ├┤ Ry(W[22]) ├»\n",
       "«     └───────────┘              └───┘         └───────────┘└───────────┘»\n",
       "«     ┌───────────┐               ┌───┐\n",
       "«q_0: ┤ Rz(W[14]) ├──■────────────┤ X ├\n",
       "«     └───────────┘┌─┴─┐          └─┬─┘\n",
       "«q_1: ─────────────┤ X ├──■─────────┼──\n",
       "«     ┌───────────┐└───┘┌─┴─┐       │  \n",
       "«q_2: ┤ Rz(W[20]) ├─────┤ X ├──■────┼──\n",
       "«     ├───────────┤     └───┘┌─┴─┐  │  \n",
       "«q_3: ┤ Rz(W[23]) ├──────────┤ X ├──■──\n",
       "«     └───────────┘          └───┘     </pre>"
      ],
      "text/plain": [
       "     ┌────────────┐┌─────────┐┌───┐┌─────────┐┌───┐┌──────────┐ ┌──────────┐»\n",
       "q_0: ┤ Rx(π*x[0]) ├┤ P(-π/2) ├┤ X ├┤ P(-π/2) ├┤ X ├┤ Rz(W[0]) ├─┤ Ry(W[1]) ├»\n",
       "     ├────────────┤├─────────┤├───┤├─────────┤├───┤├──────────┤ ├──────────┤»\n",
       "q_1: ┤ Rx(π*x[1]) ├┤ P(-π/2) ├┤ X ├┤ P(-π/2) ├┤ X ├┤ Rz(W[3]) ├─┤ Ry(W[4]) ├»\n",
       "     ├────────────┤├─────────┤├───┤├─────────┤├───┤├──────────┤ ├──────────┤»\n",
       "q_2: ┤ Rx(π*x[2]) ├┤ P(-π/2) ├┤ X ├┤ P(-π/2) ├┤ X ├┤ Rz(W[6]) ├─┤ Ry(W[7]) ├»\n",
       "     ├────────────┤├─────────┤├───┤├─────────┤├───┤├──────────┤┌┴──────────┤»\n",
       "q_3: ┤ Rx(π*x[3]) ├┤ P(-π/2) ├┤ X ├┤ P(-π/2) ├┤ X ├┤ Rz(W[9]) ├┤ Ry(W[10]) ├»\n",
       "     └────────────┘└─────────┘└───┘└─────────┘└───┘└──────────┘└───────────┘»\n",
       "«      ┌──────────┐                       ┌───┐┌───────────┐┌───────────┐»\n",
       "«q_0: ─┤ Rz(W[2]) ├──■────────────────────┤ X ├┤ Rz(W[12]) ├┤ Ry(W[13]) ├»\n",
       "«      ├──────────┤┌─┴─┐     ┌───────────┐└─┬─┘├───────────┤├───────────┤»\n",
       "«q_1: ─┤ Rz(W[5]) ├┤ X ├──■──┤ Rz(W[15]) ├──┼──┤ Ry(W[16]) ├┤ Rz(W[17]) ├»\n",
       "«      ├──────────┤└───┘┌─┴─┐└───────────┘  │  ├───────────┤├───────────┤»\n",
       "«q_2: ─┤ Rz(W[8]) ├─────┤ X ├──────■────────┼──┤ Rz(W[18]) ├┤ Ry(W[19]) ├»\n",
       "«     ┌┴──────────┤     └───┘    ┌─┴─┐      │  ├───────────┤├───────────┤»\n",
       "«q_3: ┤ Rz(W[11]) ├──────────────┤ X ├──────■──┤ Rz(W[21]) ├┤ Ry(W[22]) ├»\n",
       "«     └───────────┘              └───┘         └───────────┘└───────────┘»\n",
       "«     ┌───────────┐               ┌───┐\n",
       "«q_0: ┤ Rz(W[14]) ├──■────────────┤ X ├\n",
       "«     └───────────┘┌─┴─┐          └─┬─┘\n",
       "«q_1: ─────────────┤ X ├──■─────────┼──\n",
       "«     ┌───────────┐└───┘┌─┴─┐       │  \n",
       "«q_2: ┤ Rz(W[20]) ├─────┤ X ├──■────┼──\n",
       "«     ├───────────┤     └───┘┌─┴─┐  │  \n",
       "«q_3: ┤ Rz(W[23]) ├──────────┤ X ├──■──\n",
       "«     └───────────┘          └───┘     "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an observable\n",
    "observable = SparsePauliOp.from_list([(\"IIIZ\", 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the qnn\n",
    "qnn = EstimatorQNN(circuit=qc, observables=observable, input_params=input_params, weight_params=weight_params, input_gradients=True)  # now qnn is part of a hybrid computational graph: we should set `input_gradients=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnnWBias(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, qnn, qnn_weights_init) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.qnn = TorchConnector(qnn, initial_weights=qnn_weights_init)\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.qnn(x)\n",
    "        return self.linear(x)\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_trial = torch.Tensor([[1, 1, 0, 0]])\n",
    "# qnn_weights_init = .01 *  algorithm_globals.random.normal(size=qnn.num_weights)\n",
    "qnn_weights_init = np.pi * algorithm_globals.random.random(size=qnn.num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13666784, 0.27536034, 0.37072648, 3.02189064, 2.85439042,\n",
       "       2.19819479, 0.83525512, 3.04475739, 2.44651812, 2.25217695,\n",
       "       1.41171079, 0.85527209, 0.30282114, 2.83560906, 1.43186344,\n",
       "       0.63574326, 0.96119108, 1.81967194, 0.55534808, 2.69113314,\n",
       "       2.38295938, 2.26025954, 1.35746032, 1.97074885])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnn_weights_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QnnWBias(qnn=qnn, qnn_weights_init=qnn_weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0132], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.Tensor([0, 0, 1, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Load, preprocess and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data/parity.txt\")\n",
    "\n",
    "X = np.array(data[:, :-1])\n",
    "y = np.array(data[:, -1])\n",
    "\n",
    "# shift lables from [0, 1] to [-1, 1], to match the range of expectation values\n",
    "y = 2 * y - np.ones(len(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=algorithm_globals.random_seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.Tensor(y_train)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2892],\n",
       "        [-0.9926],\n",
       "        [-1.0385],\n",
       "        [-1.0132],\n",
       "        [-1.0385],\n",
       "        [-1.0974],\n",
       "        [-1.2769],\n",
       "        [-1.1226],\n",
       "        [-1.0283],\n",
       "        [-1.3260],\n",
       "        [-1.0132],\n",
       "        [-1.1767]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we define the accuracy function\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    \"\"\"Returns the accuracy over the dataset\n",
    "\n",
    "    Args:\n",
    "        labels (torch.Tensor): true values\n",
    "        predictions (torch.Tensor): model-predicted values\n",
    "\n",
    "    Returns:\n",
    "        float: number of accurate predictions over total\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss += 1\n",
    "\n",
    "    loss /= len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()\n",
    "opt = SGD(params=model.parameters(), lr=0.5, momentum=0.9, nesterov=True)\n",
    "\n",
    "iterations = 50\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giorgio/Phd/qnn-demo-2023/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/giorgio/Phd/qnn-demo-2023/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Loss: 4.5337868 | Accuracy: 0.5000000 \n",
      "Iter:     2 | Loss: 1.0111471 | Accuracy: 0.5000000 \n",
      "Iter:     3 | Loss: 1.5008314 | Accuracy: 0.5000000 \n",
      "Iter:     4 | Loss: 2.2876463 | Accuracy: 0.5000000 \n",
      "Iter:     5 | Loss: 1.1834501 | Accuracy: 0.5000000 \n",
      "Iter:     6 | Loss: 2.1430247 | Accuracy: 0.5000000 \n",
      "Iter:     7 | Loss: 6.3119755 | Accuracy: 0.5000000 \n",
      "Iter:     8 | Loss: 15.2277870 | Accuracy: 0.5000000 \n",
      "Iter:     9 | Loss: 5.4348764 | Accuracy: 0.5000000 \n",
      "Iter:    10 | Loss: 1.3491863 | Accuracy: 0.4166667 \n",
      "Iter:    11 | Loss: 1.4604230 | Accuracy: 0.4166667 \n",
      "Iter:    12 | Loss: 1.6295033 | Accuracy: 0.5000000 \n",
      "Iter:    13 | Loss: 1.3837266 | Accuracy: 0.5000000 \n",
      "Iter:    14 | Loss: 1.8131251 | Accuracy: 0.5000000 \n",
      "Iter:    15 | Loss: 1.4316691 | Accuracy: 0.5833333 \n",
      "Iter:    16 | Loss: 6.2255259 | Accuracy: 0.5000000 \n",
      "Iter:    17 | Loss: 3.5554576 | Accuracy: 0.5000000 \n",
      "Iter:    18 | Loss: 2.5925612 | Accuracy: 0.5000000 \n",
      "Iter:    19 | Loss: 4.8871431 | Accuracy: 0.5000000 \n",
      "Iter:    20 | Loss: 7.7926807 | Accuracy: 0.5000000 \n",
      "Iter:    21 | Loss: 13.3557377 | Accuracy: 0.5000000 \n",
      "Iter:    22 | Loss: 9.5000992 | Accuracy: 0.5000000 \n",
      "Iter:    23 | Loss: 5.9290643 | Accuracy: 0.5000000 \n",
      "Iter:    24 | Loss: 4.3824935 | Accuracy: 0.5000000 \n",
      "Iter:    25 | Loss: 2.2543769 | Accuracy: 0.5000000 \n",
      "Iter:    26 | Loss: 1.1377661 | Accuracy: 0.5000000 \n",
      "Iter:    27 | Loss: 12.0539236 | Accuracy: 0.5000000 \n",
      "Iter:    28 | Loss: 1.9577993 | Accuracy: 0.5000000 \n",
      "Iter:    29 | Loss: 4.0586262 | Accuracy: 0.5000000 \n",
      "Iter:    30 | Loss: 2.1871274 | Accuracy: 0.5000000 \n",
      "Iter:    31 | Loss: 2.2301235 | Accuracy: 0.5000000 \n",
      "Iter:    32 | Loss: 1.9205890 | Accuracy: 0.5000000 \n",
      "Iter:    33 | Loss: 6.0702581 | Accuracy: 0.5000000 \n",
      "Iter:    34 | Loss: 11.8575382 | Accuracy: 0.5000000 \n",
      "Iter:    35 | Loss: 1.4830064 | Accuracy: 0.5000000 \n",
      "Iter:    36 | Loss: 1.2256935 | Accuracy: 0.5000000 \n",
      "Iter:    37 | Loss: 1.0044159 | Accuracy: 0.5833333 \n",
      "Iter:    38 | Loss: 1.7822931 | Accuracy: 0.5000000 \n",
      "Iter:    39 | Loss: 4.1469169 | Accuracy: 0.5000000 \n",
      "Iter:    40 | Loss: 6.6159272 | Accuracy: 0.5000000 \n",
      "Iter:    41 | Loss: 9.0718651 | Accuracy: 0.5000000 \n",
      "Iter:    42 | Loss: 1.4173067 | Accuracy: 0.5000000 \n",
      "Iter:    43 | Loss: 2.3611827 | Accuracy: 0.5000000 \n",
      "Iter:    44 | Loss: 1.1176343 | Accuracy: 0.5000000 \n",
      "Iter:    45 | Loss: 1.0288328 | Accuracy: 0.3333333 \n",
      "Iter:    46 | Loss: 1.3013259 | Accuracy: 0.5000000 \n",
      "Iter:    47 | Loss: 1.7700362 | Accuracy: 0.5000000 \n",
      "Iter:    48 | Loss: 1.0191400 | Accuracy: 0.3333333 \n",
      "Iter:    49 | Loss: 1.8062199 | Accuracy: 0.5000000 \n",
      "Iter:    50 | Loss: 5.1817832 | Accuracy: 0.5000000 \n"
     ]
    }
   ],
   "source": [
    "for it in range(iterations):\n",
    "\n",
    "    # shuffle the batch indices\n",
    "    batch_index = algorithm_globals.random.integers(0, len(X_train), size=batch_size)\n",
    "\n",
    "    X_batch = X_train[batch_index]\n",
    "    y_batch = y_train[batch_index]\n",
    "\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    output = model(X_batch)\n",
    "    loss = loss_func(output, y_batch)\n",
    "    loss.backward()  # computes the gradient of the loss\n",
    "    opt.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # compute loss over train dataset\n",
    "        loss_train = loss_func(model(X_train), y_train)\n",
    "        # compute accuracy over train dataset\n",
    "        predictions = np.sign(model(X_train))\n",
    "        acc = accuracy(y_train, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Loss: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, loss_train, acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
